{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IScgbhGJwXuI"
      },
      "source": [
        "# Exercici 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mQSxNcNeyIoy"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 0\n",
        "TEST_SIZE = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7yNT9MmawRzg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtR040Pbym-N"
      },
      "source": [
        "## Apartat 1\n",
        "\n",
        "En aquest apartat es demana, utilitzant una funció incorporada en la llibreria `Sklearn`, carregar el dataset de les cares de Olivetti. Un cop s'ha carregat correctament, s'ha de fer la distinció entre dades de entrenament i dades de test, les quals ens serviran per valorar, de forma objectiva el funcionament del model. A continuació, es decideix, per tal de millorar el funcionament dels models, escalar les dades entre els valors \\[0, 1\\]. En l'enunciat es comenta que per tal d'escalar les dades s'han de dividir tots els valors entre el màxim absolut del conjunt. En canvi, s'ha cregut oportu utilitzar la funcionalitat de sklearn `MinMaxScaler`, la qual s'auto descriu com un transformador de valors entre un rang determinat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NF9QJmBPxr5s"
      },
      "outputs": [],
      "source": [
        "X, y = fetch_olivetti_faces(return_X_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lkZhGFKxyNBM"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "x3FlwX6Xypqx"
      },
      "outputs": [],
      "source": [
        "enc = OneHotEncoder().fit(y.reshape(-1, 1))\n",
        "y_encoded = enc.transform(y.reshape(-1, 1)).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lKfM5dXMx3MV"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrR-CjCV29Nr"
      },
      "source": [
        "## Apartat 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "J4sBIqtW1Hy-"
      },
      "outputs": [],
      "source": [
        "def make_pca_with_n_components(n_components, X_train, X_test):\n",
        "  pca = PCA(n_components=n_components).fit(X_train)\n",
        "  return pca.transform(X_train), pca.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "M1FZfB1D3BWA"
      },
      "outputs": [],
      "source": [
        "def create_custom_model_v2(input_size, inter_neurons, output_size):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.Input(shape=input_size))\n",
        "  model.add(keras.layers.Dense(inter_neurons, activation='relu'))\n",
        "  model.add(keras.layers.Dense(output_size, activation='softmax'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gxxaKLBAVQaQ"
      },
      "outputs": [],
      "source": [
        "def train_and_test_model(model, X_train, X_test, y_train, y_test, batch_size, epochs):\n",
        "  model.compile(optimizer=keras.optimizers.SGD(), loss=keras.losses.CategoricalCrossentropy())\n",
        "  model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,verbose=False)\n",
        "  predictions_train = model.predict(X_train, verbose=False)\n",
        "  predictions_test = model.predict(X_test, verbose=False)\n",
        "  true_predictions_train = sum([1 if np.argmax(pred) == np.argmax(real) else 0 for pred, real in zip(predictions_train, y_train)])\n",
        "  true_predictions_test = sum([1 if np.argmax(pred) == np.argmax(real) else 0 for pred, real in zip(predictions_test, y_test)])\n",
        "  return (true_predictions_train, len(y_train)), (true_predictions_test, len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NmG0mgNx1qbz"
      },
      "outputs": [],
      "source": [
        "testing_pca_values = [10, 20]\n",
        "testing_internal_neurons = [25, 50, 75, 100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf4dfkTzYiP5",
        "outputId": "63c23c5e-99ac-4e1b-da09-bf9a4be26a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "By using 10 components and 25 intermediate neurons. We have achieved the following results. Our model is able to guess the 0.99 % in training and 0.76 % in validation.\n",
            "By using 10 components and 50 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.83 % in validation.\n",
            "By using 10 components and 75 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.84 % in validation.\n",
            "By using 10 components and 100 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.84 % in validation.\n",
            "By using 20 components and 25 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.83 % in validation.\n",
            "By using 20 components and 50 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.83 % in validation.\n",
            "By using 20 components and 75 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.86 % in validation.\n",
            "By using 20 components and 100 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.88 % in validation.\n"
          ]
        }
      ],
      "source": [
        "for pca in testing_pca_values:\n",
        "  for in_neurons in testing_internal_neurons:\n",
        "    X_train_pca, X_test_pca = make_pca_with_n_components(pca, X_train, X_test)\n",
        "    model = create_custom_model_v2(pca, in_neurons, len(y_train[0]))\n",
        "    train, test = train_and_test_model(model, X_train_pca, X_test_pca, y_train, y_test, 16, 200)\n",
        "    print('By using', pca, 'components and',in_neurons, 'intermediate neurons. We have achieved the following results.',\n",
        "          'Our model is able to guess the', round(train[0]/train[1], 2), '% in training and', round(test[0]/test[1], 2), '% in validation.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI7SQiMJZ-F4"
      },
      "source": [
        "# Apartat 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NthqHNODaMsr"
      },
      "outputs": [],
      "source": [
        "def create_custom_model_v3(inter_neurons):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.Input(shape=(64,64,1,)))\n",
        "  model.add(keras.layers.Conv2D(filters=inter_neurons, kernel_size=3, strides=1, activation=\"relu\"))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(40, activation=\"softmax\"))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tCv-KnBeY9yH"
      },
      "outputs": [],
      "source": [
        "reshaped_x = X_scaled.reshape(-1,64,64,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ri_Fdf6yaIgz"
      },
      "outputs": [],
      "source": [
        "X_train_3, X_test_3, y_train, y_test = train_test_split(reshaped_x, y_encoded, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EeW5sejga2Qm"
      },
      "outputs": [],
      "source": [
        "testing_internal_neurons = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96LlQnK4aKQb",
        "outputId": "260c185d-ca80-4ee5-91bc-413ad51162b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "By using 1 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.93 % in validation.\n",
            "By using 2 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.93 % in validation.\n",
            "By using 3 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.94 % in validation.\n",
            "By using 4 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.93 % in validation.\n",
            "By using 5 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.92 % in validation.\n",
            "By using 6 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.93 % in validation.\n",
            "By using 7 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.94 % in validation.\n",
            "By using 8 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.94 % in validation.\n",
            "By using 9 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.95 % in validation.\n",
            "By using 10 intermediate neurons. We have achieved the following results. Our model is able to guess the 1.0 % in training and 0.93 % in validation.\n"
          ]
        }
      ],
      "source": [
        "for in_neurons in testing_internal_neurons:\n",
        "  model = create_custom_model_v3(in_neurons)\n",
        "  train, test = train_and_test_model(model, X_train_3, X_test_3, y_train, y_test, 16, 200)\n",
        "  print('By using', in_neurons, 'intermediate neurons. We have achieved the following results.',\n",
        "        'Our model is able to guess the', round(train[0]/train[1], 2), '% in training and', round(test[0]/test[1], 2), '% in validation.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhb8ybikRJrh"
      },
      "source": [
        "# Apartat 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GDunmVlagtw",
        "outputId": "f15eef07-6a31-4cab-dc7b-aad60ccd1d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_51 (Dense)            (None, 100)               2100      \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 40)                4040      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,140\n",
            "Trainable params: 6,140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_2 = create_custom_model_v2(20, 100, len(y_train[0]))\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIkuZL_LSvnz",
        "outputId": "970880b5-03f1-492b-f8b4-621fdf1946cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_11 (Conv2D)          (None, 62, 62, 9)         90        \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 34596)             0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 40)                1383880   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,383,970\n",
            "Trainable params: 1,383,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_3 = create_custom_model_v3(9)\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUTjAUkzTl_B"
      },
      "source": [
        "Para calcular el número de parámetros de un modelo de inteligencia artificial con capas convolucionales, primero debes conocer el tamaño de la entrada, el tamaño del kernel o filtro y el número de canales de la imagen de entrada. Además, debes conocer el número de filtros o kernels que se utilizan en cada capa y el tamaño del stride o paso utilizado por el filtro.\n",
        "\n",
        "El número de parámetros de una capa convolucional se puede calcular utilizando la siguiente fórmula:\n",
        "\n",
        "(tamaño del kernel * tamaño del kernel * número de canales de entrada + 1) * número de filtros\n",
        "\n",
        "Si tienes varias capas convolucionales en tu modelo, debes sumar el número de parámetros de cada una de ellas para obtener el número total de parámetros del modelo.\n",
        "\n",
        "Por otra parte, para calcular el número de parámetros de un modelo de inteligencia artificial con capas densas o completamente conectadas, debes conocer el tamaño de la entrada y el número de neuronas o unidades en cada capa.\n",
        "\n",
        "El número de parámetros de una capa densa se puede calcular utilizando la siguiente fórmula:\n",
        "\n",
        "(tamaño de entrada + 1) * número de neuronas\n",
        "\n",
        "Tanto en las capas convolucionales como las densas, el \"1\" se suma para tener en cuenta el término de sesgo, que es un parámetro adicional que se utiliza en cada uno de los filtros\n",
        "\n",
        "Un modelo de inteligencia artificial con un alto número de parámetros puede tener algunas ventajas y desventajas en comparación con un modelo con un número más bajo de parámetros. Algunas de las principales ventajas y desventajas se describen a continuación:\n",
        "\n",
        "- (+) Mayor capacidad de aprendizaje\n",
        "- (+) Mayor capacidad de adaptación\n",
        "- (-) Mayor tiempo de entrenamiento\n",
        "- (-) Mayor riesgo de sobreajuste\n",
        "\n",
        "En general, es importante encontrar un equilibrio adecuado entre el número de parámetros y el rendimiento del modelo. A menudo es útil utilizar técnicas como la validación cruzada y el ajuste de hiperparámetros para encontrar el número óptimo de parámetros para un modelo específico.\n",
        "\n",
        "Si no se hubiese cambiado el tamaño de los datos de entrada, en el modelo de capas densas hubiese habido (4096 + 1) * 100 = 409700 parámetros. En cambio, en el modelo convolucional, no se ha reducido el tamaño de entrada y, por lo tanto, tendríamos el mismo número de parámetros."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "AprenentatgeAutomatic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "051e2a7455ef7de55727fc6194105a963458f6ab7bfa3795f7d8c3e8e4a34bf0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
