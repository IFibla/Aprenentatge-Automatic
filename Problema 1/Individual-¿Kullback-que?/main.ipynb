{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ¿Kullback que?\n",
        "\n",
        "Cuando trabajamos con modelos que representan una distribución de probabilidad nuestro objetivo es hacer que la distribución de los datos se acerque lo más posible a las probabilidades que nos da el modelo sobre esos datos. Existen muchas maneras de calcular esa diferencia, una común es usar funciones de divergencia, entre ellas la divergencia de Kullback-Leibler es la más usada. Dadas dos distribuciones de probabilidad 𝑃 y 𝑄 se define asumiendo que sean distribuciones discretas como:\n",
        "\n",
        "$$\n",
        "KL(P|Q)=\\sum_{i=1}^{N}P(i)\\cdot \\log(\\frac{P(i)}{Q(i)}) \n",
        "$$\n",
        "\n",
        "En el caso de distribuciones continuas, simplemente substituimos el sumatorio por una integral.\n",
        "\n"
      ],
      "metadata": {
        "id": "tNlYxswldlOk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJTYZijMdg_D"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!pip uninstall scikit-learn -y\n",
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import make_classification\n",
        "import jax.numpy as np\n",
        "from jax import grad, jit"
      ],
      "metadata": {
        "id": "9f7kVGAJf12-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 1"
      ],
      "metadata": {
        "id": "tv_mwq9mg7Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Todo modelo de clasificación es una distribución de probabilidad sobre un conjunto de valores discretos, por lo que podemos ajustar un modelo probabilístico para clasificación haciendo que las probabilidades que obtenga para una muestra se ajusten a las de los datos. Usa la función make_classification de scikit-learn para crear un conjunto de datos de clasificación de dos dimensiones y 100 ejemplos. Tendrás dar un valor 0 al parámetro n_redundant y un valor 1 al parámetro n_clusters_per_class. Da un valor también al parámetro random_state para que los experimentos sean reproducibles. El problema que generará será de clasificación binaria."
      ],
      "metadata": {
        "id": "ABudX8lbfskY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Documentation to make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)\n"
      ],
      "metadata": {
        "id": "1xg3L-mJgVOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = make_classification(n_samples=100, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "ThekmQiTgRZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}